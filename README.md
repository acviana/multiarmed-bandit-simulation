# Multi-Armed Bandit Simulation

A Python-based test bed for running multi-armed bandit simulations with "epsilon-greedy" strategies and fixed reward probabilities based off of chapter 2 of Sutton and Barto's "Reinforcement Learning" (2nd Edition).

The final output of this library is a plot comparing the average results of different values of epsilon where epsilon is the probability of exploiting the best known bandit return vs randomly exploring the returns from all bandits. 
